#!/usr/bin/env node

/**
 * ScraperManager
 *
 * Orchestrates multiple video scrapers and merges their JSON outputs.
 * Does NOT scrape anything itself.
 * Does NOT know site-specific logic.
 * ONLY executes scrapers and merges results based on config.json rules.
 */

const { spawn } = require('child_process');
const fs = require('fs');
const path = require('path');

// ─────────────────────────────
// Configuration Loading
// ─────────────────────────────

/**
 * Load config.json from disk
 */
function loadConfig() {
  const configPath = path.join(__dirname, 'config.json');

  if (!fs.existsSync(configPath)) {
    throw new Error('config.json not found');
  }

  const configData = fs.readFileSync(configPath, 'utf-8');
  return JSON.parse(configData);
}

// ─────────────────────────────
// Scraper Execution
// ─────────────────────────────

/**
 * Execute a single scraper for given codes
 * Returns the JSON output from stdout
 *
 * INTERACTIVE SCRAPER SUPPORT:
 * - Scrapers can be interactive (e.g., require user input, open browser)
 * - stdin is inherited from parent terminal (user can type/press ENTER)
 * - stderr is inherited (messages are visible to user)
 * - stdout is captured for JSON parsing
 * - NO timeouts - waits indefinitely for scraper to complete
 *
 * @param {string} scraperName - Name of the scraper (e.g., "javlibrary")
 * @param {string[]} codes - Array of DVD codes to scrape
 * @returns {Promise<object[]>} - Parsed JSON array from scraper stdout
 */
function executeScraper(scraperName, codes) {
  return new Promise((resolve, reject) => {
    const scraperPath = path.join(__dirname, 'scrapers', scraperName, 'run.js');

    // Check if scraper exists
    if (!fs.existsSync(scraperPath)) {
      console.error(`[ScraperManager] Scraper not found: ${scraperPath}`);
      // Return minimal results for all codes
      resolve(codes.map(code => ({ code })));
      return;
    }

    console.error(`[ScraperManager] Executing scraper: ${scraperName}`);
    console.error(`[ScraperManager] Codes: ${codes.join(', ')}`);

    // Spawn scraper process with full interactive support
    // - stdin: 'inherit' -> user can type, press ENTER, interact with prompts
    // - stdout: 'pipe' -> capture JSON output for parsing
    // - stderr: 'inherit' -> user sees all messages, progress, instructions
    const child = spawn('node', [scraperPath, ...codes], {
      stdio: ['inherit', 'pipe', 'inherit']
    });

    let stdout = '';

    // Collect stdout
    child.stdout.on('data', (data) => {
      stdout += data.toString();
    });

    // Handle process exit
    child.on('close', (code) => {
      if (code !== 0) {
        console.error(`[ScraperManager] Scraper ${scraperName} exited with code ${code}`);
        // Return minimal results
        resolve(codes.map(c => ({ code: c })));
        return;
      }

      // Parse JSON output
      try {
        const results = JSON.parse(stdout);
        console.error(`[ScraperManager] Scraper ${scraperName} completed successfully`);
        resolve(Array.isArray(results) ? results : [results]);
      } catch (error) {
        console.error(`[ScraperManager] Failed to parse JSON from ${scraperName}: ${error.message}`);
        resolve(codes.map(c => ({ code: c })));
      }
    });

    // Handle process error
    child.on('error', (error) => {
      console.error(`[ScraperManager] Failed to execute ${scraperName}: ${error.message}`);
      resolve(codes.map(c => ({ code: c })));
    });
  });
}

// ─────────────────────────────
// Data Merging
// ─────────────────────────────

/**
 * Get priority order for a specific field
 *
 * @param {string} fieldName - Name of the field
 * @param {object} config - Configuration object
 * @returns {string[]} - Ordered list of scraper names for this field
 */
function getFieldPriority(fieldName, config) {
  // Check if field has explicit priority
  if (config.fieldPriorities && config.fieldPriorities[fieldName]) {
    return config.fieldPriorities[fieldName];
  }

  // Use global scraper order as fallback
  return config.scrapers || [];
}

/**
 * Merge data from multiple scrapers for a single DVD code
 *
 * @param {string} code - DVD code
 * @param {object[]} scraperResults - Array of {scraperName, data} objects
 * @param {object} config - Configuration object
 * @returns {object} - Merged object
 */
function mergeResults(code, scraperResults, config) {
  // Start with code field
  const merged = { code };

  // Collect all available fields
  const allFields = new Set();
  scraperResults.forEach(({ data }) => {
    Object.keys(data).forEach(field => {
      if (field !== 'code') {
        allFields.add(field);
      }
    });
  });

  // For each field, select value based on priority
  allFields.forEach(fieldName => {
    const priority = getFieldPriority(fieldName, config);

    // Find first scraper in priority order that provides this field
    for (const scraperName of priority) {
      const scraperResult = scraperResults.find(r => r.scraperName === scraperName);

      if (scraperResult && scraperResult.data[fieldName] !== undefined) {
        const value = scraperResult.data[fieldName];

        // Only add non-empty values
        if (value !== null && value !== '' && !(Array.isArray(value) && value.length === 0)) {
          merged[fieldName] = value;
          break; // Found value, stop looking
        }
      }
    }
  });

  return merged;
}

// ─────────────────────────────
// Main Orchestration
// ─────────────────────────────

/**
 * Main scraping function
 *
 * @param {string[]} codes - Array of DVD codes to scrape
 * @returns {Promise<object[]>} - Array of merged results
 */
async function scrapeAll(codes) {
  const config = loadConfig();

  // Get list of enabled scrapers
  const enabledScrapers = config.scrapers || [];

  if (enabledScrapers.length === 0) {
    console.error('[ScraperManager] No scrapers enabled in config.json');
    return codes.map(code => ({ code }));
  }

  console.error(`[ScraperManager] Enabled scrapers: ${enabledScrapers.join(', ')}`);
  console.error(`[ScraperManager] Scraping codes: ${codes.join(', ')}`);

  // Execute all enabled scrapers sequentially
  const scraperOutputs = [];

  for (const scraperName of enabledScrapers) {
    const results = await executeScraper(scraperName, codes);
    scraperOutputs.push({
      scraperName,
      results
    });
  }

  // Group results by code
  const resultsByCode = {};

  codes.forEach(code => {
    resultsByCode[code] = [];
  });

  // Collect data from each scraper for each code
  scraperOutputs.forEach(({ scraperName, results }) => {
    results.forEach(data => {
      // Match by code or dvd_id field
      const code = data.code || data.dvd_id;

      // Normalize: ensure data has 'code' field
      if (!data.code && data.dvd_id) {
        data.code = data.dvd_id;
      }

      // Find matching code (case-insensitive)
      const matchingCode = codes.find(c => c.toUpperCase() === (code || '').toUpperCase());

      if (matchingCode && resultsByCode[matchingCode]) {
        resultsByCode[matchingCode].push({
          scraperName,
          data
        });
      }
    });
  });

  // Merge results for each code
  const finalResults = codes.map(code => {
    const scraperResults = resultsByCode[code] || [];
    return mergeResults(code, scraperResults, config);
  });

  return finalResults;
}

// ─────────────────────────────
// CLI Entry Point
// ─────────────────────────────

async function main() {
  const codes = process.argv.slice(2);

  if (codes.length === 0) {
    console.error('Usage: node scraperManager.js <CODE> [CODE2] [CODE3] ...');
    console.error('Example: node scraperManager.js SDDM-943');
    console.error('Example: node scraperManager.js SDDM-943 JUR-618');
    process.exit(1);
  }

  try {
    const results = await scrapeAll(codes);

    // Output ONLY valid JSON to stdout
    console.log(JSON.stringify(results, null, 2));

  } catch (error) {
    console.error(`[ScraperManager] Fatal error: ${error.message}`);
    // On error, output minimal JSON array
    console.log(JSON.stringify(codes.map(code => ({ code })), null, 2));
    process.exit(1);
  }
}

// Run if executed directly
if (require.main === module) {
  main();
}

// Export for use as module
module.exports = { scrapeAll };
